# -*- coding: utf-8 -*-
"""U-net_biomedical_image_segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JNWX2chD54CuEfFoFFrHE06acpvt9Ro8
"""

# from google.colab import drive
# drive.mount('/content/gdrive')

# !ls '/content/gdrive/My Drive/colab_data/train/label'

import tensorflow as tf
#tf.enable_eager_execution()
from os import walk
from time import time
import numpy as np
import matplotlib.gridspec as gridspec
import matplotlib.pyplot as plt
from PIL import Image
from scipy.misc import imsave
import imageio

import imageio.core.util

# Suppress image write warnings.
def silence_imageio_warning(*args, **kwargs):
    pass

imageio.core.util._precision_warn = silence_imageio_warning


# Global variables and hyperparameters.
results_dir = '/home/simranjit/unet_biomedical_segmentation/results/1/'
dir_prefix = '/home/simranjit/unet_biomedical_segmentation/'

BATCH_SIZE = 1
EPOCHS = 30
LEARNING_RATE = 0.001
NUM_CLASSES = 2


def get_image_paths(dir_path):
  images = []
  masks = []

  test_images = []
  test_masks = []


  for (dirpath, dirnames, filenames) in walk(dir_path + 'train/image'):
      images.extend(sorted(filenames))
      break
  for (dirpath, dirnames, filenames) in walk(dir_path + 'train/label'):
      masks.extend(sorted(filenames))
      break
  for (dirpath, dirnames, filenames) in walk(dir_path + 'test/'):
      test_images.extend(sorted(filenames))
      break    
      
  test_masks = [x for x in test_images if '_predict' in x]
  test_images = [x for x in test_images if '_predict' not in x]

  images = [dir_prefix + 'train/image/' + img for img in images]
  masks = [dir_prefix + 'train/label/' + img for img in masks]

  test_images = [dir_prefix + 'test/' + img for img in test_images]
  test_masks = [dir_prefix + 'test/' + img for img in test_masks]

  assert(len(images) == len(masks))
  return [images, masks, test_images, test_masks]

[images, masks, test_images, test_masks] = get_image_paths(dir_prefix)  


def load_and_preprocess_image(path):
  def preprocess_image(image):
    image = tf.image.decode_png(image, channels=1)
    img_final = tf.image.resize_images(image, [512, 512])
    img_final = img_final/255.0
    return img_final

  image = tf.read_file(path)
  return preprocess_image(image)

def select_device(use_gpu=True):
    from tensorflow.python.client import device_lib
    print(device_lib.list_local_devices())
    device = '/device:GPU:0' if use_gpu else '/CPU:0'
    print('Using device: ', device)
    return device

def unet(X, num_classes):
  """
  U-Net architecture. The logits layer is returned unscaled since tensorflow sparse_softmax_cross_entropy_with_logits methods
  efficiently calculates the softmax probabilities and cross entropy loss.
  X: Tensor of dimensions [N, H, W, 1]
  """
  # Contract 1
  conv1 = tf.layers.conv2d(inputs=X, filters=64, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  conv1 = tf.layers.conv2d(inputs=conv1, filters=64, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=[2, 2])
  
  # Contract 2
  conv2 = tf.layers.conv2d(inputs=pool1, filters=128, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  conv2 = tf.layers.conv2d(inputs=conv2, filters=128, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=[2, 2])

  # Contract 3
  conv3 = tf.layers.conv2d(inputs=pool2, filters=256, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  conv3 = tf.layers.conv2d(inputs=conv3, filters=256, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=[2, 2])

  # Contract 4
  conv4 = tf.layers.conv2d(inputs=pool3, filters=512, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  conv4 = tf.layers.conv2d(inputs=conv4, filters=512, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  pool4 = tf.layers.max_pooling2d(inputs=conv4, pool_size=[2, 2], strides=[2, 2])

  # Same level
  conv5 = tf.layers.conv2d(inputs=pool4, filters=1024, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  conv5 = tf.layers.conv2d(inputs=conv5, filters=1024, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)

  # Expanding path 1
  up1 = tf.layers.conv2d_transpose(conv5, filters=512, kernel_size=2, strides=2)
  up1 = tf.concat([conv4, up1], axis=3)
  up1 = tf.layers.conv2d(inputs=up1, filters=512, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  up1 = tf.layers.conv2d(inputs=up1, filters=512, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)

  # Expanding path 2
  up2 = tf.layers.conv2d_transpose(up1, filters=256, kernel_size=2, strides=2)
  up2 = tf.concat([conv3, up2], axis=3)
  up2 = tf.layers.conv2d(inputs=up2, filters=256, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  up2 = tf.layers.conv2d(inputs=up2, filters=256, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)

  # Expanding path 3
  up3 = tf.layers.conv2d_transpose(up2, filters=128, kernel_size=2, strides=2)
  up3 = tf.concat([conv2, up3], axis=3)
  up3 = tf.layers.conv2d(inputs=up3, filters=128, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  up3 = tf.layers.conv2d(inputs=up3, filters=128, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)

  # Expanding path 4
  up4 = tf.layers.conv2d_transpose(up3, filters=64, kernel_size=2, strides=2)
  up4 = tf.concat([conv1, up4], axis=3)
  up4 = tf.layers.conv2d(inputs=up4, filters=64, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)
  up4 = tf.layers.conv2d(inputs=up4, filters=64, kernel_size=[3, 3], padding="same", activation=tf.nn.relu)

  # Final layer
  final = tf.layers.conv2d(inputs=up4, filters=num_classes, kernel_size=[1, 1], padding="same", activation=None)
  # final = tf.layers.conv2d(inputs=final, filters=1, kernel_size=[1, 1], padding="same", activation=tf.nn.sigmoid)
  # logits = tf.reshape(final, (-1, num_classes))
  return final



device = select_device(use_gpu=True)

# Generate train and test datasets iterators.
# Train
image_path_ds = tf.data.Dataset.from_tensor_slices(images)
mask_path_ds = tf.data.Dataset.from_tensor_slices(masks)

image_ds = image_path_ds.map(load_and_preprocess_image)
mask_ds = mask_path_ds.map(load_and_preprocess_image)

train_ds = tf.data.Dataset.zip((image_ds, mask_ds, image_path_ds))
train_ds = train_ds.batch(BATCH_SIZE)

# Test
test_image_path_ds = tf.data.Dataset.from_tensor_slices(test_images)
test_mask_path_ds = tf.data.Dataset.from_tensor_slices(test_masks)

test_image_ds = test_image_path_ds.map(load_and_preprocess_image)
test_mask_ds = test_mask_path_ds.map(load_and_preprocess_image)

test_ds = tf.data.Dataset.zip((test_image_ds, test_mask_ds, test_image_path_ds))
test_ds = test_ds.batch(BATCH_SIZE)

# Train iterator
iterator = train_ds.make_initializable_iterator()
images_batch, masks_batch, paths_batch = iterator.get_next()

# Test iterator
test_iterator = test_ds.make_initializable_iterator()
test_images_batch, test_masks_batch, test_paths_batch = test_iterator.get_next()

originals = []
results = []


# Set the training op.
with tf.device(device):
  X = tf.placeholder(tf.float32, [None, 512, 512, 1])
  Y = tf.placeholder(tf.int32, [None, 512, 512])

  S = unet(X, NUM_CLASSES)
  # S0 = tf.round(S1)
  # S0 = 1 - S1
  # S = tf.concat([S0, S1], axis=3)
  # losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=S)
  # loss = tf.math.reduce_mean(losses)
  # mean_iou, conf = tf.metrics.mean_iou(Y, S0, 2)
  # intersection = tf.math.reduce_sum(tf.math.multiply(S0, Y))
  # union = tf.reduce_sum(S0) + tf.reduce_sum(Y) - intersection
  # loss = -IOU_(S1, Y)
  # global_step = tf.train.get_or_create_global_step()
  S1 = tf.reshape(S, [-1, NUM_CLASSES])
  Y1 = tf.reshape(Y, [-1])
  loss_vector = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y1, logits=S1)
  loss = tf.reduce_mean(loss_vector)
  optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)
  train_op = optimizer.minimize(loss)


# The training loop.
config = tf.ConfigProto(allow_soft_placement = True)
with tf.Session(config=config) as sess:
    # Initialize variables that will live in the graph
    sess.run(tf.global_variables_initializer())
    for epoch in range(EPOCHS):
        print('epoch {:>4d}/{:>4d}'.format(epoch, EPOCHS))
        sess.run(iterator.initializer)
        epoch_time = time()
        it = 0
        while True:
          try:        
            img_batch, msk_batch, path_batch = sess.run([images_batch, masks_batch, paths_batch])
            sess.run(train_op, feed_dict={X: img_batch, Y: msk_batch.reshape([-1, 512, 512])})
            if it%20==0:
              loss_val, res = sess.run([loss, S], feed_dict={X: img_batch, Y: msk_batch.reshape([-1, 512, 512])})
              res = res.argmax(axis=3).reshape([512, 512]).astype(float)
              if epoch % 5 == 0:
                file_name = results_dir + "e_{0}_".format(epoch) + path_batch[0].decode("utf-8").split('/')[-1]
                imageio.imwrite(file_name, res)
                print("\tSaved file {0}".format(file_name))
              print("\tIteration {0} Loss: {1}".format(it, loss_val))
          except tf.errors.OutOfRangeError:
            break
          it += 1

    print("Done training. Generating results for test images.")
    
    # Generate predictions for test images.
    test_num = 0
    sess.run(test_iterator.initializer)
    while True:
      try:        
        test_img_batch, test_msk_batch, test_path_batch = sess.run([test_images_batch, test_masks_batch, test_paths_batch])
        res = sess.run(S, feed_dict={X: test_img_batch})
        res = res.argmax(axis=3).reshape([512, 512]).astype(float)
        file_name = results_dir + "test_" + test_path_batch[0].decode("utf-8").split('/')[-1]
        imageio.imwrite(file_name, res)
        # print(tf.argmax(S, axis=3).shape)
        # res = tf.reshape(tf.argmax(S, axis=3), [512, 512])
        # print(res.shape)
        # tf.cast(res, tf.float32)
        # print(res)
        results.append(res)
        originals.append(test_img_batch.reshape([512, 512]))
      except tf.errors.OutOfRangeError:
        break
        
      print("Generated results for test images.")
